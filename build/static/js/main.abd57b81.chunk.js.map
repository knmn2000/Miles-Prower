{"version":3,"sources":["components/LandingButtons.jsx","views/Landing.jsx","components/ScraperButtons.jsx","preset/presets.js","components/FormButtons.jsx","components/ScraperForm.jsx","actions/details.jsx","actions/types.jsx","views/Scraper.jsx","App.js","serviceWorker.js","reducers/scraper.jsx","reducers/rootReducers.jsx","index.js"],"names":["LandingButtons","text","link","thisDOM","useRef","className","role","to","pathname","target","ref","onMouseMove","e","leftOffset","current","getBoundingClientRect","left","btnWidth","offsetWidth","myPosX","pageX","newClass","clearedClassList","replace","trim","Hover","label","Landing","console","log","ScraperButton","handleClickExit","onClick","onMouseLeave","preset","template","String","raw","selenium_imports","pagination","infinite_scrolling","html_response","FormButtons","style","width","connect","state","details","scraper","editName","value","dispatch","type","payload","err","editClass","editCountry","editRegulator","editRegFull","editUrl","open","useState","editorCode","setEditorCode","name","setName","regulator","setRegulator","country","setCountry","regulator_full_name","regFull","setRegFull","main_url","url","setUrl","class_name","scraperClass","setClass","useEffect","placeholder","onChange","height","fontSize","mode","theme","newValue","wrapEnabled","editorProps","$blockScrolling","setOptions","enableBasicAutocompletion","enableLiveAutocompletion","enableSnippets","editTemplate","editType","setValue","newsButton","setNews","regButton","setReg","handleClick","split","join","zIndex","App","exact","path","component","Scraper","Boolean","window","location","hostname","match","initState","loading","error","combineReducers","action","middleware","thunk","store","createStore","rootReducers","composeWithDevTools","applyMiddleware","ReactDOM","render","StrictMode","document","getElementById","navigator","serviceWorker","ready","then","registration","unregister","catch","message"],"mappings":"0SAEaA,G,MAAiB,SAAC,GAAoB,IAAlBC,EAAiB,EAAjBA,KAAMC,EAAW,EAAXA,KAC/BC,EAAUC,mBAqBhB,OACE,6BACE,yBAAKC,UAAU,WACb,yBAAKC,KAAK,SAASD,UAAU,aAC3B,kBAAC,IAAD,CACEE,GAAI,CAAEC,SAAUN,GAChBO,OAAiB,aAATP,EAAsB,KAAO,SACrCG,UAAU,MACVK,IAAKP,EACLQ,YAAa,SAACC,GAAD,OA7BT,SAACA,GACb,IAAIC,EAAaV,EAAQW,QAAQC,wBAAwBC,KACrDC,EAAWd,EAAQW,QAAQI,YAC3BC,EAASP,EAAEQ,MACXC,EAAW,GAEbA,EADEF,EAASN,EAAa,GAAMI,EACnB,WAEPE,EAASN,EAAa,IAAOI,EACpB,YAEA,aAIf,IAAIK,EAAmBnB,EAAQW,QAAQT,UACpCkB,QAAQ,kCAAmC,IAC3CC,OACHrB,EAAQW,QAAQT,UAAYiB,EAAmB,IAAMD,EAWzBI,CAAMb,KAE1B,0BAAMP,UAAU,aACd,0BAAMA,UAAU,mBACd,0BAAMA,UAAU,eACd,0BAAMA,UAAU,oBAAoBqB,MAAOzB,aCpChD0B,EAAU,WAErB,OADAC,QAAQC,IAAI,uBAEV,yBAAKxB,UAAU,WACb,0BAAMA,UAAU,gBAAhB,SACA,yBAAKA,UAAU,mBACb,kBAAC,EAAD,CACEJ,KAAK,uBACLC,KAAK,sCAEP,kBAAC,EAAD,CAAgBD,KAAK,kBAAkBC,KAAK,gB,wBCXvC4B,EAAgB,SAAC,GAAc,IAAZ7B,EAAW,EAAXA,KACxBE,EAAUC,mBAqBV2B,EAAkB,SAACnB,GACvB,IACIU,EAAmBnB,EAAQW,QAAQT,UACpCkB,QAAQ,kCAAmC,IAC3CC,OACHrB,EAAQW,QAAQT,UAAYiB,iBAE9B,OACE,6BACE,yBAAKjB,UAAU,WACb,yBAAKC,KAAK,SAASD,UAAU,wBAC3B,4BACEA,UAAU,MACVK,IAAKP,EACLQ,YAAa,SAACC,GAAD,OAlCT,SAACA,GACb,IAAIC,EAAaV,EAAQW,QAAQC,wBAAwBC,KACrDC,EAAWd,EAAQW,QAAQI,YAC3BC,EAASP,EAAEQ,MACXC,EAAW,GAEbA,EADEF,EAASN,EAAa,GAAMI,EACnB,WAEPE,EAASN,EAAa,IAAOI,EACpB,YAEA,aAIf,IAAIK,EAAmBnB,EAAQW,QAAQT,UACpCkB,QAAQ,kCAAmC,IAC3CC,OACHrB,EAAQW,QAAQT,UAAYiB,EAAmB,IAAMD,EAgBzBI,CAAMb,IAC1BoB,QAAS,SAACpB,GAAD,OAAOmB,KAChBE,aAAc,SAACrB,GAAD,OAAOmB,MAErB,0BAAM1B,UAAU,aACd,0BAAMA,UAAU,mBACd,0BAAMA,UAAU,eACd,0BAAMA,UAAU,oBAAoBqB,MAAOzB,Y,s/xBC5C7D,IA+beiC,EA/bF,CACXC,SAAUC,OAAOC,IAAT,KAgVRC,iBAAiB,stCA0CjBC,WAAW,67BA4BXC,mBAAmB,+wBAqBnBC,cAAc,0jBC3aHC,G,kBAAc,SAAC,GAAc,IAAZzC,EAAW,EAAXA,KACtBE,EAAUC,mBAoBV2B,EAAkB,SAACnB,GACvB,IACIU,EAAmBnB,EAAQW,QAAQT,UACpCkB,QAAQ,kCAAmC,IAC3CC,OACHrB,EAAQW,QAAQT,UAAYiB,iBAE9B,OACE,6BACE,yBAAKjB,UAAU,WACb,yBAAKC,KAAK,SAASD,UAAU,wBAC3B,4BACEA,UAAU,MACVsC,MAAO,CACLC,MAAO,OAETlC,IAAKP,EACLQ,YAAa,SAACC,GAAD,OApCT,SAACA,GACb,IAAIC,EAAaV,EAAQW,QAAQC,wBAAwBC,KACrDC,EAAWd,EAAQW,QAAQI,YAC3BC,EAASP,EAAEQ,MACXC,EAAW,GAEbA,EADEF,EAASN,EAAa,GAAMI,EACnB,WAEPE,EAASN,EAAa,IAAOI,EACpB,YAEA,aAGf,IAAIK,EAAmBnB,EAAQW,QAAQT,UACpCkB,QAAQ,kCAAmC,IAC3CC,OACHrB,EAAQW,QAAQT,UAAYiB,EAAmB,IAAMD,EAmBzBI,CAAMb,IAC1BoB,QAAS,SAACpB,GAAD,OAAOmB,KAChBE,aAAc,SAACrB,GAAD,OAAOmB,MAErB,0BAAM1B,UAAU,aACd,0BAAMA,UAAU,mBACd,0BAAMA,UAAU,eACd,0BAAMA,UAAU,oBAAoBqB,MAAOzB,aCkM9C4C,eALS,SAACC,GACvB,MAAO,CACLC,QAASD,EAAME,QAAQD,WAGa,CACtCE,SC1MsB,SAACC,GAAD,OAAW,SAACC,GAClC,IACEA,EAAS,CACPC,KC1CmB,YD2CnBC,QAASH,IAEX,MAAOI,GACP1B,QAAQC,IAAIyB,GACZH,EAAS,CACPC,KAAM,QACNC,QAASC,ODiMbC,UCnJuB,SAACL,GAAD,OAAW,SAACC,GACnC,IACEA,EAAS,CACPC,KC7FoB,aD8FpBC,QAASH,IAEX,MAAOI,GACP1B,QAAQC,IAAIyB,GACZH,EAAS,CACPC,KAAM,QACNC,QAASC,OD0IbE,YCtIyB,SAACN,GAAD,OAAW,SAACC,GACrC,IACEA,EAAS,CACPC,KC7GsB,eD8GtBC,QAASH,IAEX,MAAOI,GACP1B,QAAQC,IAAIyB,GACZH,EAAS,CACPC,KAAM,QACNC,QAASC,OD6HbG,cC/L2B,SAACP,GAAD,OAAW,SAACC,GACvC,IACEA,EAAS,CACPC,KCtDkB,WDuDlBC,QAASH,IAEX,MAAOI,GACP1B,QAAQC,IAAIyB,GACZH,EAAS,CACPC,KAAM,QACNC,QAASC,ODsLbI,YClLyB,SAACR,GAAD,OAAW,SAACC,GACrC,IACEA,EAAS,CACPC,KCrEuB,gBDsEvBC,QAASH,IAEX,MAAOI,GACP1B,QAAQC,IAAIyB,GACZH,EAAS,CACPC,KAAM,QACNC,QAASC,ODyKbK,QCrKqB,SAACT,GAAD,OAAW,SAACC,GACjC,IACEA,EAAS,CACPC,KChFkB,WDiFlBC,QAASH,IAEX,MAAOI,GACP1B,QAAQC,IAAIyB,GACZH,EAAS,CACPC,KAAM,QACNC,QAASC,QDqJAT,EA9NK,SAAC,GASd,IARLe,EAQI,EARJA,KACAX,EAOI,EAPJA,SACAM,EAMI,EANJA,UACAC,EAKI,EALJA,YACAC,EAII,EAJJA,cACAC,EAGI,EAHJA,YACAC,EAEI,EAFJA,QACAZ,EACI,EADJA,QACI,EACgCc,mBAAS,uBADzC,mBACGC,EADH,KACeC,EADf,OAEoBF,mBAASd,EAAQiB,MAFrC,mBAEGA,EAFH,KAESC,EAFT,OAG8BJ,mBAASd,EAAQmB,WAH/C,mBAGGA,EAHH,KAGcC,EAHd,OAI0BN,mBAASd,EAAQqB,SAJ3C,mBAIGA,EAJH,KAIYC,EAJZ,OAK0BR,mBAASd,EAAQuB,qBAL3C,mBAKGC,EALH,KAKYC,EALZ,OAMkBX,mBAASd,EAAQ0B,UANnC,mBAMGC,EANH,KAMQC,EANR,OAO6Bd,mBAASd,EAAQ6B,YAP9C,mBAOGC,EAPH,KAOiBC,EAPjB,KAsCJ,OA3BAC,qBAAU,WACRd,EAAQD,GACRG,EAAaD,GACbG,EAAWD,GACXI,EAAWD,GACXI,EAAOD,GACPI,EAASD,KACR,CAAC9B,EAASiB,EAAMa,EAAcH,EAAKH,EAASH,EAASF,IAqBtD,oCACE,yBAAK7D,UAAWuD,EAAO,sBAAwB,UAC7C,yBAAKvD,UAAU,WACb,yBAAKA,UAAU,eACb,0BAAMA,UAAU,WACd,wBAAIA,UAAU,eAAd,mBACA,yBAAKA,UAAU,aACb,yBAAKA,UAAU,YACb,2BACE2D,KAAK,OACLZ,KAAK,OACL4B,YAAY,mBACZ3E,UAAU,cACV4E,SAAU,SAACrE,GAhC7B,IAAoBsC,EAiCAe,EAAQrD,EAAEH,OAAOyC,OAjCjBA,EAkCW,CACTc,KAAMpD,EAAEH,OAAOyC,MACfgB,UAAWA,EACXU,WAAYC,EACZP,oBAAqBC,EACrBE,SAAUC,EACVN,QAASA,GAvCtBnB,EAASC,MA4CF,2BACEc,KAAK,UACLZ,KAAK,OACL4B,YAAY,UACZ3E,UAAU,cACV4E,SAAU,SAACrE,GA5C7B,IAAuBsC,EA6CHmB,EAAWzD,EAAEH,OAAOyC,OA7CjBA,EA8CW,CACZc,KAAMA,EACNE,UAAWA,EACXU,WAAYC,EACZP,oBAAqBC,EACrBE,SAAUC,EACVN,QAASxD,EAAEH,OAAOyC,OAnD/BM,EAAYN,MAwDL,2BACEc,KAAK,sBACLZ,KAAK,OACL4B,YAAY,sBACZ3E,UAAU,cACV4E,SAAU,SAACrE,GA3D7B,IAAuBsC,EA4DHsB,EAAW5D,EAAEH,OAAOyC,OA5DjBA,EA6DW,CACZc,KAAMA,EACNE,UAAWA,EACXU,WAAYC,EACZP,oBAAqB1D,EAAEH,OAAOyC,MAC9BuB,SAAUC,EACVN,QAASA,GAlEtBV,EAAYR,OAuEP,yBAAK7C,UAAU,YACb,2BACE2D,KAAK,WACLZ,KAAK,OACL4B,YAAY,WACZ3E,UAAU,cACV4E,SAAU,SAACrE,GA3E7B,IAAmBsC,EA4ECyB,EAAO/D,EAAEH,OAAOyC,OA5EjBA,EA6EW,CACRc,KAAMA,EACNE,UAAWA,EACXU,WAAYC,EACZP,oBAAqBC,EACrBE,SAAU7D,EAAEH,OAAOyC,MACnBkB,QAASA,GAlFtBT,EAAQT,MAuFD,2BACEc,KAAK,MACLZ,KAAK,OACL4B,YAAY,yBACZ3E,UAAU,cACV4E,SAAU,SAACrE,GAtG7B,IAAyBsC,EAuGLiB,EAAavD,EAAEH,OAAOyC,OAvGjBA,EAwGW,CACdc,KAAMA,EACNE,UAAWtD,EAAEH,OAAOyC,MACpB0B,WAAYC,EACZP,oBAAqBC,EACrBE,SAAUC,EACVN,QAASA,GA7GtBX,EAAcP,MAkHP,2BACEc,KAAK,YACLZ,KAAK,OACL4B,YAAY,aACZ3E,UAAU,cACV4E,SAAU,SAACrE,GA5G7B,IAAqBsC,EA6GD4B,EAASlE,EAAEH,OAAOyC,OA7GjBA,EA8GW,CACVc,KAAMA,EACNE,UAAWA,EACXU,WAAYhE,EAAEH,OAAOyC,MACrBoB,oBAAqBC,EACrBE,SAAUC,EACVN,QAASA,GAnHtBb,EAAUL,UA2HX,yBAAK7C,UAAU,eACb,yBAAKA,UAAU,gBACb,yBAAK2B,QAAS,kBAAM+B,EAAc7B,EAAOI,oBACvC,kBAAC,EAAD,CAAarC,KAAK,sBAEpB,yBAAK+B,QAAS,kBAAM+B,EAAc7B,EAAOK,cACvC,kBAAC,EAAD,CAAatC,KAAK,gBAEpB,yBAAK+B,QAAS,kBAAM+B,EAAc7B,EAAOM,sBACvC,kBAAC,EAAD,CAAavC,KAAK,wBAEpB,yBAAK+B,QAAS,kBAAM+B,EAAc7B,EAAOO,iBACvC,kBAAC,EAAD,CAAaxC,KAAK,oBAGtB,kBAAC,IAAD,CACE0C,MAAO,CACLuC,OAAQ,OACRtC,MAAO,QAETuC,SAAU,GACVC,KAAK,SACLC,MAAM,UACNJ,SA9KZ,SAAkBK,GAChB1D,QAAQC,IAAI,SAAUyD,IA8KZC,aAAa,EACbvB,KAAK,eACLd,MAAOY,EACP0B,YAAa,CAAEC,iBAAiB,GAChCC,WAAY,CACVC,2BAA2B,EAC3BC,0BAA0B,EAC1BC,gBAAgB,YGnHjBhD,eAPS,SAACC,GACvB,MAAO,CACLX,SAAUW,EAAME,QAAQb,SACxBiB,KAAMN,EAAME,QAAQI,QAIgB,CAAE0C,aF7Ed,SAAC5C,GAAD,OAAW,SAACC,GACtC,IACEA,EAAS,CACPC,KCrBuB,gBDsBvBC,QAASH,IAEX,MAAOI,GACP1B,QAAQC,IAAIyB,GACZH,EAAS,CACPC,KAAM,QACNC,QAASC,OEmEyCyC,SF5FhC,SAAC7C,GAAD,OAAW,SAACC,GAClC,IACEA,EAAS,CACPC,KCLmB,YDMnBC,QAASH,IAEX,MAAOI,GACP1B,QAAQC,IAAIyB,GACZH,EAAS,CACPC,KAAM,QACNC,QAASC,QEkFAT,EA7FC,SAAC,GAAgD,IAA9CV,EAA6C,EAA7CA,SAAU2D,EAAmC,EAAnCA,aAAcC,EAAqB,EAArBA,SAAU3C,EAAW,EAAXA,KAAW,MAIpCS,mBAAS1B,GAJ2B,mBAIvDe,EAJuD,KAIhD8C,EAJgD,OAKhCnC,oBAAS,GALuB,mBAKvDoC,EALuD,KAK3CC,EAL2C,OAMlCrC,oBAAS,GANyB,mBAMvDsC,EANuD,KAM5CC,EAN4C,KAO9D,SAASC,EAAYjD,GACN,SAATA,EACF8C,GAASD,GACS,QAAT7C,GACTgD,GAAQD,GAEVJ,EAAS3C,GAmBX,OAjBA2B,qBAAU,WAEN5C,EADW,SAATiB,EACSjB,EACRmE,MAAM,uBACNC,KAAK,iBACLD,MAAM,oCACNC,KAAK,8BAEGpE,EACRmE,MAAM,iBACNC,KAAK,uBACLD,MAAM,8BACNC,KAAK,oCAEVP,EAAS7D,GACT2D,EAAa3D,KACZ,CAAC6D,EAAUF,EAAc1C,EAAMiD,IAEhC,yBAAKhG,UAAU,UACb,kBAAC,IAAD,CACEsC,MAAO,CACLuC,OAAQ,QACRtC,MAAO,OACP4D,OAAQ,OAEVrB,SAAU,GACVC,KAAK,SACLC,MAAM,UACNJ,SA1CN,SAAkBK,GAChB1D,QAAQC,IAAI,SAAUyD,IA0ClBC,aAAa,EACbvB,KAAK,eACLd,MAAOA,EACPsC,YAAa,CAAEC,iBAAiB,GAChCC,WAAY,CACVC,2BAA2B,EAC3BC,0BAA0B,EAC1BC,gBAAgB,KAGpB,yBACExF,UACE8F,GAAaF,EAAa,4BAA8B,aAG1D,yBAAK5F,UAAU,SACb,yBACEA,UAAW8F,EAAY,uBAAyB,aAChDnE,QAAS,WACFmE,GACHE,EAAY,UAIhB,kBAAC,EAAD,CAAepG,KAAK,kBAEtB,yBACEI,UAAW4F,EAAa,uBAAyB,aACjDjE,QAAS,WACFiE,GACHI,EAAY,SAIhB,kBAAC,EAAD,CAAepG,KAAK,oBAI1B,kBAAC,EAAD,CAAa2D,QAAMuC,IAAaF,SCzEvBQ,MAbf,WACE,OACE,kBAAC,IAAD,KACE,yBAAKpG,UAAU,OACb,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAOqG,OAAK,EAACC,KAAK,IAAIC,UAAWjF,IACjC,kBAAC,IAAD,CAAO+E,OAAK,EAACC,KAAK,WAAWC,UAAWC,QCC9BC,QACW,cAA7BC,OAAOC,SAASC,UAEe,UAA7BF,OAAOC,SAASC,UAEhBF,OAAOC,SAASC,SAASC,MACvB,2D,WCNAC,EAAY,CAChBhF,SAAUD,EAAOC,SACjBY,QAAS,CACPiB,KAAM,cACNE,UAAW,aACXE,QAAS,UACTE,oBAAqB,sBACrBG,SAAU,mCACVG,WAAY,gBAEdxB,KAAM,MACNgE,QAAS,KACTC,MAAO,MAELlF,EAAW,KCvBAmF,4BAAgB,CAC7BtE,QDuBa,WAAsC,IAA5BF,EAA2B,uDAAnBqE,EAAWI,EAAQ,uCAClD,OAAQA,EAAOnE,MACb,IJrBqB,YIsBnB,OAAO,2BACFN,GADL,IAEEsE,SAAS,EACThE,KAAMmE,EAAOlE,UAEjB,IJ5ByB,gBI6BvB,OAAO,2BACFP,GADL,IAEEsE,SAAS,EACTjF,SAAUoF,EAAOlE,UAErB,IJzCqB,YI+CnB,OALAlB,EAAWW,EAAMX,SACdmE,MADQ,mBACUxD,EAAMC,QAAQiB,OAChCuC,KAFQ,mBAESgB,EAAOlE,QAAQW,OAChCsC,MAHQ,yBAGgBxD,EAAMC,QAAQiB,OACtCuC,KAJQ,yBAIegB,EAAOlE,QAAQW,OAClC,2BACFlB,GADL,IAEEX,WACAiF,SAAS,EACTrE,QAASwE,EAAOlE,UAEpB,IJhDsB,aIgEpB,OAfAlB,EAAWW,EAAMX,SACdmE,MADQ,gBACOxD,EAAMC,QAAQ6B,WADrB,qBAER2B,KAFQ,gBAEMgB,EAAOlE,QAAQuB,WAFrB,qBAGR0B,MAHQ,kDAIoCxD,EAAMC,QAAQ6B,aAE1D2B,KANQ,kDAOoCgB,EAAOlE,QAAQuB,aAE3D0B,MATQ,4CASmCxD,EAAMC,QAAQ6B,aACzD2B,KAVQ,4CAUkCgB,EAAOlE,QAAQuB,aACzD0B,MAXQ,cAWKxD,EAAMC,QAAQ6B,aAC3B2B,KAZQ,cAYIgB,EAAOlE,QAAQuB,aAC3B0B,MAbQ,mBAaUxD,EAAMC,QAAQ6B,aAChC2B,KAdQ,mBAcSgB,EAAOlE,QAAQuB,aAC5B,2BACF9B,GADL,IAEEX,WACAiF,SAAS,EACTrE,QAASwE,EAAOlE,UAEpB,IJxEwB,eI4EtB,OAHAlB,EAAWW,EAAMX,SACdmE,MADQ,qBACYxD,EAAMC,QAAQqB,QAD1B,MAERmC,KAFQ,qBAEWgB,EAAOlE,QAAQe,QAF1B,MAGJ,2BACFtB,GADL,IAEEX,WACAiF,SAAS,EACTrE,QAASwE,EAAOlE,UAEpB,IJnFoB,WIuFlB,OAHAlB,EAAWW,EAAMX,SACdmE,MADQ,uBACcxD,EAAMC,QAAQmB,UAD5B,MAERqC,KAFQ,uBAEagB,EAAOlE,QAAQa,UAF5B,MAGJ,2BACFpB,GADL,IAEEX,WACAiF,SAAS,EACTrE,QAASwE,EAAOlE,UAEpB,IJ9FyB,gBIkGvB,OAHAlB,EAAWW,EAAMX,SACdmE,MADQ,iCACwBxD,EAAMC,QAAQuB,oBADtC,MAERiC,KAFQ,iCAEuBgB,EAAOlE,QAAQiB,oBAFtC,MAGJ,2BACFxB,GADL,IAEEX,WACAiF,SAAS,EACTrE,QAASwE,EAAOlE,UAEpB,IJrGoB,WIyGlB,OAHAlB,EAAWW,EAAMX,SACdmE,MADQ,sBACaxD,EAAMC,QAAQ0B,SAD3B,MAER8B,KAFQ,sBAEYgB,EAAOlE,QAAQoB,SAF3B,MAGJ,2BACF3B,GADL,IAEEX,WACAiF,SAAS,EACTrE,QAASwE,EAAOlE,UAEpB,IJ1GiB,QI4GjB,QACE,OAAOP,ME3GP0E,EAAa,CAACC,KACdC,EAAQC,sBACZC,EAHmB,GAKnBC,8BAAoBC,kBAAe,WAAf,EAAmBN,KAEzCO,IAASC,OACP,kBAAC,IAAMC,WAAP,KACE,kBAAC,IAAD,CAAUP,MAAOA,GACf,kBAAC,EAAD,QAGJQ,SAASC,eAAe,SH4GpB,kBAAmBC,WACrBA,UAAUC,cAAcC,MACrBC,MAAK,SAAAC,GACJA,EAAaC,gBAEdC,OAAM,SAAArB,GACLzF,QAAQyF,MAAMA,EAAMsB,c","file":"static/js/main.abd57b81.chunk.js","sourcesContent":["import React, { useRef } from \"react\";\nimport { Link } from \"react-router-dom\";\nexport const LandingButtons = ({ text, link }) => {\n  const thisDOM = useRef();\n  const Hover = (e) => {\n    var leftOffset = thisDOM.current.getBoundingClientRect().left;\n    var btnWidth = thisDOM.current.offsetWidth;\n    var myPosX = e.pageX;\n    var newClass = \"\";\n    if (myPosX < leftOffset + 0.3 * btnWidth) {\n      newClass = \"btn-left\";\n    } else {\n      if (myPosX > leftOffset + 0.65 * btnWidth) {\n        newClass = \"btn-right\";\n      } else {\n        newClass = \"btn-center\";\n      }\n    }\n    // remove prev class\n    var clearedClassList = thisDOM.current.className\n      .replace(/btn-center|btn-right|btn-left/gi, \"\")\n      .trim();\n    thisDOM.current.className = clearedClassList + \" \" + newClass;\n  };\n  return (\n    <div>\n      <div className=\"wrapper\">\n        <div role=\"button\" className=\"retro-btn\">\n          <Link\n            to={{ pathname: link }}\n            target={link === \"/scraper\" ? null : \"_blank\"}\n            className=\"btn\"\n            ref={thisDOM}\n            onMouseMove={(e) => Hover(e)}\n          >\n            <span className=\"btn-inner\">\n              <span className=\"content-wrapper\">\n                <span className=\"btn-content\">\n                  <span className=\"btn-content-inner\" label={text}></span>\n                </span>\n              </span>\n            </span>\n          </Link>\n        </div>\n      </div>\n    </div>\n  );\n};\n","import React from \"react\";\nimport { LandingButtons } from \"../components/LandingButtons\";\nexport const Landing = () => {\n  console.log(\"knmn2000 says Hello\");\n  return (\n    <div className=\"landing\">\n      <span className=\"landing-text\">SONIC</span>\n      <div className=\"landing-buttons\">\n        <LandingButtons\n          text=\"Check Sonic instance\"\n          link=\"https://sonic.radicali.io/1/jobs/\"\n        />\n        <LandingButtons text=\"Build a Scraper\" link=\"/scraper\" />\n      </div>\n    </div>\n  );\n};\n","import React, { useRef } from \"react\";\nexport const ScraperButton = ({ text }) => {\n  const thisDOM = useRef();\n  const Hover = (e) => {\n    var leftOffset = thisDOM.current.getBoundingClientRect().left;\n    var btnWidth = thisDOM.current.offsetWidth;\n    var myPosX = e.pageX;\n    var newClass = \"\";\n    if (myPosX < leftOffset + 0.3 * btnWidth) {\n      newClass = \"btn-left\";\n    } else {\n      if (myPosX > leftOffset + 0.65 * btnWidth) {\n        newClass = \"btn-right\";\n      } else {\n        newClass = \"btn-center\";\n      }\n    }\n    // remove prev class\n    var clearedClassList = thisDOM.current.className\n      .replace(/btn-center|btn-right|btn-left/gi, \"\")\n      .trim();\n    thisDOM.current.className = clearedClassList + \" \" + newClass;\n  };\n  const handleClickExit = (e) => {\n    var newClass = \"btn-center\";\n    var clearedClassList = thisDOM.current.className\n      .replace(/btn-center|btn-right|btn-left/gi, \"\")\n      .trim();\n    thisDOM.current.className = clearedClassList + \" \" + newClass;\n  };\n  return (\n    <div>\n      <div className=\"wrapper\">\n        <div role=\"button\" className=\"retro-btn lg primary\">\n          <button\n            className=\"btn\"\n            ref={thisDOM}\n            onMouseMove={(e) => Hover(e)}\n            onClick={(e) => handleClickExit(e)}\n            onMouseLeave={(e) => handleClickExit(e)}\n          >\n            <span className=\"btn-inner\">\n              <span className=\"content-wrapper\">\n                <span className=\"btn-content\">\n                  <span className=\"btn-content-inner\" label={text}></span>\n                </span>\n              </span>\n            </span>\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n};\n","var preset = {\n  template: String.raw`import re\nimport time\nimport scrapy\n\nfrom sonic.settings import ItemType\nfrom sonic.sonic_utils import SonicUtils\n\n# BOTH SCRAPER AND TEST TEMPLATES AVAILABLE\nclass ScraperClass(scrapy.Spider):\n    # VERIFY NAMES AND ABBREVIATIONS\n    name = \"X_NAME_ABBR\"\n    regulator = \"REG (CTRY)\"\n    country = \"COUNTRY\"\n    regulator_full_name = \"REGULATOR_FULL_NAME\"\n    #### REGEX DATE PATTERNS -\n    pattern = re.compile(r\"[\\d]{1,2} [ADFJMNOS]\\w* [\\d]{4}\")\n    patternV2  = re.compile(r\"[\\d]{1,2}\\/[\\d]{1,2}\\/[\\d]{1,2}\")\n    patternV3 = re.compile(r\"([12]\\d{3}.(0[1-9]|1[0-2]).(0[1-9]|[12]\\d|3[01]))\")\n    patternV4 = re.compile(r\"\\d{2}\\s[a-zA-Z]{3}\\s\\d{4}\")\n    ####\n    main_url = \"https://www.regulatorWebsite.com\"\n    sheet_name = \"X_NAME_ABBR\"\n    fieldnames = [\n        \"regulator\",\n        \"regulator_full_name\",\n        \"country\",\n        \"activity\",\n        \"document_type\",\n        # match field names from zoho sheet\n    ]\n    target_urls = []\n    hardcoded_dates = {}  # possible ? getDates() : hardCodeDates()\n    utils = SonicUtils()\n    item_type = ItemType.REGULATION.value\n\n    def _parse_method_template(self, response):\n        \"\"\"method to parse urls obtained from zoho and fetch \n           titles, links and dates\n        Args:\n            response (object): scrapy object containing response from the url\n\n        Yields:\n            [sonic.items.SonicItem] -- contains meta for each object scraped.\n        \"\"\"\n        meta = response.meta\n        url = response.url\n        for element in elements:\n            link = element.xpath(\"//*LINK\").extract_first()\n            title = element.xpath(\"//*TITLE\").extract_first()\n            date = response.xpath(\"//*DATE\").extract()\n            link = response.urljoin(link)\n            meta.update(\n                {\n                    \"title\": title,\n                    \"link\": link,\n                    \"date\": date,\n                    \"response_url\": response.url,\n                    \"is_html\": False,\n                }\n            )\n            yield self.utils.create_items(**meta)\n\n    def _parse_method_template_with_pagination(self, response):\n        \"\"\"method to parse urls obtained from zoho and fetch \n           titles, links and dates\n        Args:\n            response (object): scrapy object containing response from the url\n\n        Yields:\n            [sonic.items.SonicItem] -- contains meta for each object scraped.\n        \"\"\"\n        meta = response.meta\n        url = response.url\n        for element in elements:\n            link = element.xpath(\"//*LINK\").extract_first()\n            title = element.xpath(\"//*TITLE\").extract_first()\n            date = response.xpath(\"//*DATE\").extract()\n            link = response.urljoin(link)\n            meta.update(\n                {\n                    \"title\": title,\n                    \"link\": link,\n                    \"date\": date,\n                    \"response_url\": response.url,\n                    \"is_html\": False,\n                }\n            )\n            yield self.utils.create_items(**meta)\n\n        next_page = response.xpath(\"//*PAGINATION_LINK\").extract_first()\n        if next_page is not None:  # Change condition as required\n            next_page_url = response.urljoin(next_page)\n            yield scrapy.Request(\n                next_page_url, callback=self._parse_consultation, meta=meta\n            )\n\n    # VERSION 1 HTML CONTENT METHOD\n    def _parse_html_content(self, response):\n        self.driver.get(response.url)\n        WebDriverWait(self.driver, self.delay).until(\n            EC.presence_of_element_located((By.XPATH, \"//RELEVANT XPATH\"))\n        )\n        response = HtmlResponse(\n            self.driver.current_url, body=self.driver.page_source, encoding=\"utf-8\"\n        )\n        title = element.xpath(\"//*TITLE\").extract_first()\n        date = response.xpath(\"//*DATE\").extract()\n        html_content = \" \".join(response.xpath(\"//XPATH TO TEXT CONTENTS\").extract())\n        html_meta.update(\n            {\n                \"title\": title,\n                \"html_content\": html_content,\n                \"is_html\": True,\n                \"link\": response.url,\n                \"date\": date,\n                \"ignore_link_check\": True,\n            }\n        )\n        yield self.utils.create_items(**html_meta)\n\n    def start_requests(self):\n        \"\"\"Scrapy method to start requests, call parsers and pass meta info based on the urls fetched from zoho.\n\n        Yields:\n            scrapy.Request: scrapy Request constructor to complete the download and pass in the parsers in callback\n        \"\"\"\n        urls, meta_list = self.utils.read_from_zoho(\n            country_from_sheet_flag=True,\n            sheet_name=self.sheet_name,\n            fieldnames=self.fieldnames,\n            regulator_full_name=self.regulator_full_name,\n            regulator=self.regulator,\n            country=self.country,\n        )\n\n        for url, meta in zip(urls, meta_list):\n            meta.update({\"item_type\": self.item_type})\n            document_type = meta.get(\"document_type\")\n            activity = meta.get(\"activity\")\n            if document_type == \"doc_type\":\n                yield scrapy.Request(\n                    url, callback=self._parse_method_template, meta=meta\n                )\n            if activity == \"activity\":\n                yield scrapy.Request(\n                    url, callback=self._parse_method_template, meta=meta\n                )\n            if \"keyword\" in url:\n                yield scrapy.Request(\n                    url, callback=self._parse_method_template, meta=meta\n                )\n            if url in self.target_urls:\n                yield scrapy.Request(\n                    url, callback=self._parse_method_template, meta=meta\n                )\n##########################################################\n# TEMPLATE FOR TESTS \nimport logging\nimport time\nimport unittest\n\nimport pytest\nimport requests\nimport vcr\nfrom scrapy.http import HtmlResponse, Request\n\nfrom sonic.pipelines import SonicPipeline\nfrom sonic.settings import ItemType\nfrom sonic.spiders.regulation_spiders import ScraperClass \n\n# @pytest.mark.vcr(match_on=[\"method\", \"scheme\", \"host\", \"query\"])\nclass TestScraperClass:\n    spider = ScraperClass()\n    example_url = \"https://www.dummy.com\"\n    another_url = \"https://www.dummy.com\"\n    other_url = \"https://www.dummy.com\"\n    list_links = [\"https://www.dummy.com\", \"https://www.dummy.com\"]\n\n    start_urls_list = [\n        example_url,\n        other_url,\n        another_url,\n    ]\n    parse_list = [\n        example_url,\n        other_url,\n        another_url,\n    ]\n    meta = {\n        \"item_type\": ItemType.REGULATION.value,\n        \"regulator\": \"SC (MY)\",\n    }\n    spider.wait_time = 0\n    pipeline = SonicPipeline()\n    # TEST METHOD TEMPLATES\n    # @pytest.mark.vcr(match_on=[\"method\", \"scheme\", \"host\", \"query\"])\n    # @pytest.mark.slow\n    # @pytest.mark.vcr\n    def test_parse_method_name(self):\n        response = requests.get(self.example_url)\n        request = Request(url=self.example_url, meta=self.meta,)\n        response = HtmlResponse(\n            url=self.example_url,\n            request=request,\n            body=response.content,\n            encoding=\"utf-8\",\n        )\n        gen = self.spider._parse_example(response)\n        results = []\n        for item in gen:\n            self.pipeline.process_item(item, self.spider)\n            results.append(item)\n        assert len(results) == 1\n\n    # @pytest.mark.vcr(match_on=[\"method\", \"scheme\", \"host\", \"query\"])\n    # @pytest.mark.slow\n    # @pytest.mark.vcr\n    def test_parse_method_other_name(self, requests_session, mock_time):\n        results = []\n        for url in self.list_of_links:\n            response = requests_session.get(url)\n            request = Request(url=url, meta=self.meta)\n            response = HtmlResponse(\n                url=url, request=request, body=response.content, encoding=\"utf-8\",\n            )\n            gen = self.spider._relevant_method(response)\n            for item in gen:\n                self.pipeline.process_item(item, self.spider)\n                results.append(item)\n        assert len(results) == 1\n\n    # IF METHOD HAS BOTH PAYLOAD YIELDS AND REQUEST YIELDS **\n    # @pytest.mark.vcr(match_on=[\"method\", \"scheme\", \"host\", \"query\"])\n    # @pytest.mark.slow\n    # @pytest.mark.vcr\n    def test_parse_method(self, requests_session, mock_time):\n        results = []\n        for url in self.list_links:\n            response = requests_session.get(url)\n            request = Request(url=url, meta=self.meta)\n            response = HtmlResponse(\n                url=url, request=request, body=response.content, encoding=\"utf-8\",\n            )\n            gen = self.spider._parse_papers(response)\n            for item in gen:\n                try:\n                    self.pipeline.process_item(item, self.spider)\n                except AttributeError:\n                    pass\n                results.append(item)\n        assert len(results) == 1\n\n    # IF METHOD HAS \"ENTRIES\" ARGUMENT\n    # @pytest.mark.vcr(match_on=[\"method\", \"scheme\", \"host\", \"query\"])\n    # @pytest.mark.slow\n    # @pytest.mark.vcr\n    def test_parse_pdf_entries(self, requests_session, mock_time):\n        results = []\n        response = requests_session.get(self.example_url)\n        request = Request(url=self.example_url, meta=self.meta)\n        response = HtmlResponse(\n            url=self.example_url,\n            request=request,\n            body=response.content,\n            encoding=\"utf-8\",\n        )\n        entries = response.xpath(\"//XPATH FOR ENTRIES\")\n        gen = self.spider._parse_method(response, entries)\n        for request in gen:\n            self.pipeline.process_item(request, self.spider)\n            results.append(request)\n        assert len(results) == 1\n\n    # PARSE TEST METHODS\n    # @pytest.mark.vcr(match_on=[\"method\", \"scheme\", \"host\", \"query\"])\n    def test_parse(self, monkeypatch, requests_session):\n        metas = []\n        url_list = self.parse_list\n        for url in url_list:\n            if url == self.consultation_url:\n                meta.update({\"document_type\": \"Consultation Paper\"})\n            else:\n                meta.update({\"document_type\": \"dummy\"})\n            response = requests_session.get(url)\n            request = Request(url=url, meta=self.meta)\n            response = HtmlResponse(\n                url=url, request=request, body=response.content, encoding=\"utf-8\",\n            )\n            if url == self.consultation_url:\n                feedback = \"parse consultation called\"\n                monkeypatch.setattr(\n                    self.spider, \"_parse_consultations\", lambda s: feedback,\n                )\n            if \"something\" in url:\n                feedback = \"parse something called\"\n                monkeypatch.setattr(\n                    self.spider,\n                    \"_parse_something\",\n                    lambda s, entries: feedback,\n                    \"dummy\",\n                )\n            if url == self.something_else:\n                feedback = \"_something_else called\"\n                monkeypatch.setattr(self.spider, \"_something_else\", lambda s: feedback)\n            result = self.spider.parse(response)\n            if type(result) == str:\n                assert result == feedback\n            else:\n                metas.append([i for i in result])\n\n    # START REQUEST TEST METHODS\n    def test_start_requests(self, monkeypatch):\n        for url in self.start_urls_list:\n            monkeypatch.setattr(\n                self.spider.utils, \"read_from_zoho\", lambda **args: ([url], [self.meta])\n            )\n            gen = self.spider.start_requests()\n            for response in gen:\n                if url == self.example_url:\n                    assert response.callback.__name__ == \"_parse_this_url\"\n                if \"/something\" in url:\n                    assert response.callback.__name__ == \"_parse_that_url\"\n\n    # @pytest.mark.vcr(match_on=[\"method\", \"scheme\", \"host\", \"query\"])\n    def test_start_requests(self, monkeypatch):\n        response = []\n        for url in self.start_urls_list:\n            monkeypatch.setattr(\n                self.spider.utils,\n                \"read_from_zoho\",\n                lambda **kwargs: ([url], self.meta),\n            )\n            gen = self.spider.start_requests()\n            response.append([i for i in gen])\n        assert len(response) >= 1\n`,\n  selenium_imports: `import logging\nimport re\nimport time\nfrom os.path import abspath, dirname, join\n\nimport dateparser\nimport scrapy\nfrom scrapy.http import HtmlResponse\nfrom selenium import webdriver\nfrom selenium.common.exceptions import TimeoutException\nfrom selenium.webdriver.common.action_chains import ActionChains\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.firefox.options import Options\nfrom selenium.webdriver.remote.remote_connection import LOGGER\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.support.ui import Select, WebDriverWait\n\nfrom sonic.settings import ItemType\nfrom sonic.sonic_utils import SonicUtils\n\nLOGGER.setLevel(logging.ERROR)\n\nPATH_DIR = dirname(abspath(__file__))\nGECKODRIVER_PATH = abspath(join(PATH_DIR, \"../../geckodriver\"))\n\n#### DEFINE CLASS NAME AND VARIABLES \n\ndef __init__(self, *args, **kwargs):\n        options = Options()\n        options.headless = True\n        self.driver = webdriver.Firefox(\n            options=options, executable_path=GECKODRIVER_PATH\n        )\n\ndef __del__(self):\n    self.driver.quit()\n\n#### INSIDE PARSER METHOD \nmeta = response.meta\nsource = response.url\nself.driver.get(source)\n`,\n  pagination: `\nnext_page = response.xpath('//LINK TO NEXT PAGE').extract_first()\nif next_page is not None:\nnext_page_url = response.urljoin(next_page)\nyield scrapy.Request(next_page_url, callback=self._parse_method, meta=meta)\n\n###### VER 2\n\n# FROM HTML_SGX_SG\nnext_page = response.xpath('//LINK TO NEXT PAGE')\nlast_page = next_page.xpath(\"./CONDITION FOR LAST PAGE\").extract_first()\nif last_page is None:\n    next_page_url = next_page.xpath(\"./@href\").extract_first()\n    if next_page_url is not None:\n        next_page_url = response.urljoin(next_page_url)\n        yield scrapy.Request(\n            next_page_url, callback=self._parse_method, meta=meta\n        )\n\n###### VER 3\n\n# FROM N_BAFIN_GE\nnext_page = response.xpath(\n            '//*NEXT PAGE LINK'\n        ).extract_first()\nif next_page is not None:\n    next_page_url = response.urljoin(next_page)\n    yield scrapy.Request(next_page_url, callback=self._parse_method, meta=meta)`,\n  infinite_scrolling: `  \n# FROM N_ECB_EU\n\nmeta = response.meta\nself.driver.get(response.url)\nself.driver.implicitly_wait(self.wait_time)\nbody = self.driver.page_source\nactions = ActionChains(self.driver)\nresponse = HtmlResponse(\n    self.driver.current_url, body=body, encoding=\"utf-8\"\n)  # handing over html response from selenium\nsnippets = self.driver.find_elements_by_xpath(\"//*ELEMENTS THAT LOAD ON SCROLLING\")\nfor snippet in snippets:\n    # loading parts of the page by scrolling them into view\n    self.driver.execute_script(\"arguments[0].scrollIntoView();\", snippet)\n    entries = snippet.find_elements_by_xpath(\"./FIND NEXT ELEMENT\")\n    for entry in entries:\n        try:\n            # scraping code \n        except:\n            self.driver.implicitly_wait(self.wait_time)`,\n  html_response: `\nmeta = response.meta\nself.driver.get(response.url)\nself.driver.implicitly_wait(self.wait_time)\nbody = self.driver.page_source\nactions = ActionChains(self.driver)\nresponse = HtmlResponse(\n    self.driver.current_url, body=body, encoding=\"utf-8\"\n)  # handing over html response from selenium\n\n#### With Explicit wait\nWebDriverWait(self.driver, self.delay).until(\n     EC.presence_of_element_located((By.XPATH, 'Xpath to be found'))\n)\nbody = self.driver.page_source\nresponse = HtmlResponse(\n    self.driver.current_url, body=body, encoding=\"utf-8\"\n)`,\n};\nexport default preset;\n","import React, { useRef } from \"react\";\nexport const FormButtons = ({ text }) => {\n  const thisDOM = useRef();\n  const Hover = (e) => {\n    var leftOffset = thisDOM.current.getBoundingClientRect().left;\n    var btnWidth = thisDOM.current.offsetWidth;\n    var myPosX = e.pageX;\n    var newClass = \"\";\n    if (myPosX < leftOffset + 0.3 * btnWidth) {\n      newClass = \"btn-left\";\n    } else {\n      if (myPosX > leftOffset + 0.65 * btnWidth) {\n        newClass = \"btn-right\";\n      } else {\n        newClass = \"btn-center\";\n      }\n    }\n    var clearedClassList = thisDOM.current.className\n      .replace(/btn-center|btn-right|btn-left/gi, \"\")\n      .trim();\n    thisDOM.current.className = clearedClassList + \" \" + newClass;\n  };\n  const handleClickExit = (e) => {\n    var newClass = \"btn-center\";\n    var clearedClassList = thisDOM.current.className\n      .replace(/btn-center|btn-right|btn-left/gi, \"\")\n      .trim();\n    thisDOM.current.className = clearedClassList + \" \" + newClass;\n  };\n  return (\n    <div>\n      <div className=\"wrapper\">\n        <div role=\"button\" className=\"retro-btn sm primary\">\n          <button\n            className=\"btn\"\n            style={{\n              width: \"95%\",\n            }}\n            ref={thisDOM}\n            onMouseMove={(e) => Hover(e)}\n            onClick={(e) => handleClickExit(e)}\n            onMouseLeave={(e) => handleClickExit(e)}\n          >\n            <span className=\"btn-inner\">\n              <span className=\"content-wrapper\">\n                <span className=\"btn-content\">\n                  <span className=\"btn-content-inner\" label={text}></span>\n                </span>\n              </span>\n            </span>\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n};\n","import React, { useState, useEffect } from \"react\";\nimport { connect } from \"react-redux\";\nimport AceEditor from \"react-ace\";\nimport preset from \"../preset/presets.js\";\nimport \"ace-builds/src-noconflict/mode-python\";\nimport \"ace-builds/src-noconflict/theme-monokai\";\nimport \"ace-builds/src-noconflict/ext-language_tools\";\nimport { FormButtons } from \"./FormButtons\";\nimport {\n  editName,\n  editClass,\n  editCountry,\n  editRegulator,\n  editRegFull,\n  editUrl,\n} from \"../actions/details\";\nimport PropTypes from \"prop-types\";\n\nconst ScraperForm = ({\n  open,\n  editName,\n  editClass,\n  editCountry,\n  editRegulator,\n  editRegFull,\n  editUrl,\n  details,\n}) => {\n  const [editorCode, setEditorCode] = useState(\"#Template Code here\");\n  const [name, setName] = useState(details.name);\n  const [regulator, setRegulator] = useState(details.regulator);\n  const [country, setCountry] = useState(details.country);\n  const [regFull, setRegFull] = useState(details.regulator_full_name);\n  const [url, setUrl] = useState(details.main_url);\n  const [scraperClass, setClass] = useState(details.class_name);\n  function onChange(newValue) {\n    console.log(\"change\", newValue);\n  }\n  useEffect(() => {\n    setName(name);\n    setRegulator(regulator);\n    setCountry(country);\n    setRegFull(regFull);\n    setUrl(url);\n    setClass(scraperClass);\n  }, [details, name, scraperClass, url, regFull, country, regulator]);\n\n  function modifyName(value) {\n    return editName(value);\n  }\n  function modifyRegulator(value) {\n    return editRegulator(value);\n  }\n  function modifyCountry(value) {\n    return editCountry(value);\n  }\n  function modifyRegFull(value) {\n    return editRegFull(value);\n  }\n  function modifyUrl(value) {\n    return editUrl(value);\n  }\n  function modifyClass(value) {\n    return editClass(value);\n  }\n  return (\n    <>\n      <div className={open ? \"slider slider-slide\" : \"slider\"}>\n        <div className=\"sidebar\">\n          <div className=\"sidebar-one\">\n            <form className=\"details\">\n              <h1 className=\"form-header\">Scraper details</h1>\n              <div className=\"form-grid\">\n                <div className=\"grid-one\">\n                  <input\n                    name=\"name\"\n                    type=\"text\"\n                    placeholder=\"Name [R_ABC_XY1]\"\n                    className=\"input-field\"\n                    onChange={(e) => {\n                      setName(e.target.value);\n                      modifyName({\n                        name: e.target.value,\n                        regulator: regulator,\n                        class_name: scraperClass,\n                        regulator_full_name: regFull,\n                        main_url: url,\n                        country: country,\n                      });\n                    }}\n                  />\n\n                  <input\n                    name=\"country\"\n                    type=\"text\"\n                    placeholder=\"Country\"\n                    className=\"input-field\"\n                    onChange={(e) => {\n                      setCountry(e.target.value);\n                      modifyCountry({\n                        name: name,\n                        regulator: regulator,\n                        class_name: scraperClass,\n                        regulator_full_name: regFull,\n                        main_url: url,\n                        country: e.target.value,\n                      });\n                    }}\n                  />\n\n                  <input\n                    name=\"regulator_full_name\"\n                    type=\"text\"\n                    placeholder=\"Regulator full name\"\n                    className=\"input-field\"\n                    onChange={(e) => {\n                      setRegFull(e.target.value);\n                      modifyRegFull({\n                        name: name,\n                        regulator: regulator,\n                        class_name: scraperClass,\n                        regulator_full_name: e.target.value,\n                        main_url: url,\n                        country: country,\n                      });\n                    }}\n                  />\n                </div>\n                <div className=\"grid-two\">\n                  <input\n                    name=\"main url\"\n                    type=\"text\"\n                    placeholder=\"Main URL\"\n                    className=\"input-field\"\n                    onChange={(e) => {\n                      setUrl(e.target.value);\n                      modifyUrl({\n                        name: name,\n                        regulator: regulator,\n                        class_name: scraperClass,\n                        regulator_full_name: regFull,\n                        main_url: e.target.value,\n                        country: country,\n                      });\n                    }}\n                  />\n\n                  <input\n                    name=\"reg\"\n                    type=\"text\"\n                    placeholder=\"regulator [REG (CTRY)]\"\n                    className=\"input-field\"\n                    onChange={(e) => {\n                      setRegulator(e.target.value);\n                      modifyRegulator({\n                        name: name,\n                        regulator: e.target.value,\n                        class_name: scraperClass,\n                        regulator_full_name: regFull,\n                        main_url: url,\n                        country: country,\n                      });\n                    }}\n                  />\n\n                  <input\n                    name=\"classname\"\n                    type=\"text\"\n                    placeholder=\"Class name\"\n                    className=\"input-field\"\n                    onChange={(e) => {\n                      setClass(e.target.value);\n                      modifyClass({\n                        name: name,\n                        regulator: regulator,\n                        class_name: e.target.value,\n                        regulator_full_name: regFull,\n                        main_url: url,\n                        country: country,\n                      });\n                    }}\n                  />\n                </div>\n              </div>\n            </form>\n          </div>\n          <div className=\"sidebar-two\">\n            <div className=\"form-buttons\">\n              <div onClick={() => setEditorCode(preset.selenium_imports)}>\n                <FormButtons text=\"selenium imports\" />\n              </div>\n              <div onClick={() => setEditorCode(preset.pagination)}>\n                <FormButtons text=\"pagination\" />\n              </div>\n              <div onClick={() => setEditorCode(preset.infinite_scrolling)}>\n                <FormButtons text=\"infinite scrolling\" />\n              </div>\n              <div onClick={() => setEditorCode(preset.html_response)}>\n                <FormButtons text=\"HTML response\" />\n              </div>\n            </div>\n            <AceEditor\n              style={{\n                height: \"45vh\",\n                width: \"100%\",\n              }}\n              fontSize={14}\n              mode=\"python\"\n              theme=\"monokai\"\n              onChange={onChange}\n              wrapEnabled={true}\n              name=\"SonicScraper\"\n              value={editorCode}\n              editorProps={{ $blockScrolling: true }}\n              setOptions={{\n                enableBasicAutocompletion: true,\n                enableLiveAutocompletion: true,\n                enableSnippets: true,\n              }}\n            />\n          </div>\n        </div>\n      </div>\n    </>\n  );\n};\nScraperForm.propTypes = {\n  editName: PropTypes.func.isRequired,\n  editCountry: PropTypes.func.isRequired,\n  editRegulator: PropTypes.func.isRequired,\n  editRegFull: PropTypes.func.isRequired,\n  editUrl: PropTypes.func.isRequired,\n  editClass: PropTypes.func.isRequired,\n  details: PropTypes.object.isRequired,\n};\nconst mapStateToProps = (state) => {\n  return {\n    details: state.scraper.details,\n  };\n};\nexport default connect(mapStateToProps, {\n  editName,\n  editClass,\n  editCountry,\n  editRegulator,\n  editRegFull,\n  editUrl,\n})(ScraperForm);\n","import {\n  EDIT_NAME,\n  EDIT_REG_FULL,\n  EDIT_REG,\n  EDIT_COUNTRY,\n  EDIT_URL,\n  EDIT_CLASS,\n  EDIT_TEMPLATE,\n  EDIT_TYPE,\n} from \"./types\";\nexport const editType = (value) => (dispatch) => {\n  try {\n    dispatch({\n      type: EDIT_TYPE,\n      payload: value,\n    });\n  } catch (err) {\n    console.log(err);\n    dispatch({\n      type: \"ERROR\",\n      payload: err,\n    });\n  }\n};\n\nexport const editTemplate = (value) => (dispatch) => {\n  try {\n    dispatch({\n      type: EDIT_TEMPLATE,\n      payload: value,\n    });\n  } catch (err) {\n    console.log(err);\n    dispatch({\n      type: \"ERROR\",\n      payload: err,\n    });\n  }\n};\nexport const editName = (value) => (dispatch) => {\n  try {\n    dispatch({\n      type: EDIT_NAME,\n      payload: value,\n    });\n  } catch (err) {\n    console.log(err);\n    dispatch({\n      type: \"ERROR\",\n      payload: err,\n    });\n  }\n};\nexport const editRegulator = (value) => (dispatch) => {\n  try {\n    dispatch({\n      type: EDIT_REG,\n      payload: value,\n    });\n  } catch (err) {\n    console.log(err);\n    dispatch({\n      type: \"ERROR\",\n      payload: err,\n    });\n  }\n};\nexport const editRegFull = (value) => (dispatch) => {\n  try {\n    dispatch({\n      type: EDIT_REG_FULL,\n      payload: value,\n    });\n  } catch (err) {\n    console.log(err);\n    dispatch({\n      type: \"ERROR\",\n      payload: err,\n    });\n  }\n};\nexport const editUrl = (value) => (dispatch) => {\n  try {\n    dispatch({\n      type: EDIT_URL,\n      payload: value,\n    });\n  } catch (err) {\n    console.log(err);\n    dispatch({\n      type: \"ERROR\",\n      payload: err,\n    });\n  }\n};\nexport const editClass = (value) => (dispatch) => {\n  try {\n    dispatch({\n      type: EDIT_CLASS,\n      payload: value,\n    });\n  } catch (err) {\n    console.log(err);\n    dispatch({\n      type: \"ERROR\",\n      payload: err,\n    });\n  }\n};\nexport const editCountry = (value) => (dispatch) => {\n  try {\n    dispatch({\n      type: EDIT_COUNTRY,\n      payload: value,\n    });\n  } catch (err) {\n    console.log(err);\n    dispatch({\n      type: \"ERROR\",\n      payload: err,\n    });\n  }\n};\n","export const EDIT_NAME = \"EDIT_NAME\";\nexport const EDIT_REG_FULL = \"EDIT_REG_FULL\";\nexport const EDIT_REG = \"EDIT_REG\";\nexport const EDIT_COUNTRY = \"EDIT_COUNTRY\";\nexport const EDIT_URL = \"EDIT_URL\";\nexport const EDIT_CLASS = \"EDIT_CLASS\";\nexport const EDIT_DETAILS = \"EDIT_DETAILS\";\nexport const EDIT_TEMPLATE = \"EDIT_TEMPLATE\";\nexport const EDIT_TYPE = \"EDIT TYPE\";\nexport const ERROR = \"ERROR\";\n","import React, { useState, useEffect } from \"react\";\nimport AceEditor from \"react-ace\";\nimport { connect } from \"react-redux\";\nimport { ScraperButton } from \"../components/ScraperButtons\";\nimport ScraperForm from \"../components/ScraperForm\";\nimport \"ace-builds/src-noconflict/mode-python\";\nimport \"ace-builds/src-noconflict/theme-monokai\";\nimport \"ace-builds/src-noconflict/ext-language_tools\";\nimport { editTemplate, editType } from \"../actions/details\";\nconst Scraper = ({ template, editTemplate, editType, type }) => {\n  function onChange(newValue) {\n    console.log(\"change\", newValue);\n  }\n  const [value, setValue] = useState(template);\n  const [newsButton, setNews] = useState(false);\n  const [regButton, setReg] = useState(false);\n  function handleClick(type) {\n    if (type === \"news\") {\n      setNews(!newsButton);\n    } else if (type === \"reg\") {\n      setReg(!regButton);\n    }\n    editType(type);\n  }\n  useEffect(() => {\n    if (type === \"news\") {\n      template = template\n        .split(\"ItemType.REGULATION\")\n        .join(\"ItemType.NEWS\")\n        .split(\"sonic.spiders.regulation_spiders\")\n        .join(\"sonic.spiders.news_spiders\");\n    } else {\n      template = template\n        .split(\"ItemType.NEWS\")\n        .join(\"ItemType.REGULATION\")\n        .split(\"sonic.spiders.news_spiders\")\n        .join(\"sonic.spiders.regulation_spiders\");\n    }\n    setValue(template);\n    editTemplate(template);\n  }, [setValue, editTemplate, type, handleClick]);\n  return (\n    <div className=\"editor\">\n      <AceEditor\n        style={{\n          height: \"100vh\",\n          width: \"40vw\",\n          zIndex: \"999\",\n        }}\n        fontSize={12}\n        mode=\"python\"\n        theme=\"monokai\"\n        onChange={onChange}\n        wrapEnabled={true}\n        name=\"SonicScraper\"\n        value={value}\n        editorProps={{ $blockScrolling: true }}\n        setOptions={{\n          enableBasicAutocompletion: true,\n          enableLiveAutocompletion: true,\n          enableSnippets: true,\n        }}\n      />\n      <div\n        className={\n          regButton || newsButton ? \"customize customize-slide\" : \"customize\"\n        }\n      >\n        <div className=\"group\">\n          <div\n            className={regButton ? \"scraperBtn invisible\" : \"scraperBtn\"}\n            onClick={() => {\n              if (!regButton) {\n                handleClick(\"news\");\n              }\n            }}\n          >\n            <ScraperButton text=\"News Scraper\" />\n          </div>\n          <div\n            className={newsButton ? \"scraperBtn invisible\" : \"scraperBtn\"}\n            onClick={() => {\n              if (!newsButton) {\n                handleClick(\"reg\");\n              }\n            }}\n          >\n            <ScraperButton text=\"Reg. Scraper\" />\n          </div>\n        </div>\n      </div>\n      <ScraperForm open={regButton || newsButton ? true : false} />\n    </div>\n  );\n};\nconst mapStateToProps = (state) => {\n  return {\n    template: state.scraper.template,\n    type: state.scraper.type,\n  };\n};\n\nexport default connect(mapStateToProps, { editTemplate, editType })(Scraper);\n","import React from \"react\";\nimport { BrowserRouter as Router, Route, Switch } from \"react-router-dom\";\nimport \"./App.scss\";\nimport { Landing } from \"./views/Landing\";\nimport Scraper from \"./views/Scraper\";\nfunction App() {\n  return (\n    <Router>\n      <div className=\"App\">\n        <Switch>\n          <Route exact path=\"/\" component={Landing} />\n          <Route exact path=\"/scraper\" component={Scraper} />\n        </Switch>\n      </div>\n    </Router>\n  );\n}\n\nexport default App;\n","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.0/8 are considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\nexport function register(config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl, config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl, config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl, {\n    headers: { 'Service-Worker': 'script' },\n  })\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready\n      .then(registration => {\n        registration.unregister();\n      })\n      .catch(error => {\n        console.error(error.message);\n      });\n  }\n}\n","import preset from \"../preset/presets.js\";\nimport {\n  EDIT_NAME,\n  EDIT_REG_FULL,\n  EDIT_REG,\n  EDIT_COUNTRY,\n  EDIT_URL,\n  EDIT_CLASS,\n  EDIT_TEMPLATE,\n  EDIT_TYPE,\n  ERROR,\n} from \"../actions/types\";\nconst initState = {\n  template: preset.template,\n  details: {\n    name: \"X_NAME_ABBR\",\n    regulator: \"REG (CTRY)\",\n    country: \"COUNTRY\",\n    regulator_full_name: \"REGULATOR_FULL_NAME\",\n    main_url: \"https://www.regulatorWebsite.com\",\n    class_name: \"ScraperClass\",\n  },\n  type: \"reg\",\n  loading: null,\n  error: null,\n};\nvar template = null;\nexport default function (state = initState, action) {\n  switch (action.type) {\n    case EDIT_TYPE:\n      return {\n        ...state,\n        loading: false,\n        type: action.payload,\n      };\n    case EDIT_TEMPLATE:\n      return {\n        ...state,\n        loading: false,\n        template: action.payload,\n      };\n    case EDIT_NAME:\n      template = state.template\n        .split(` name = \"${state.details.name}`)\n        .join(` name = \"${action.payload.name}`)\n        .split(` sheet_name = \"${state.details.name}`)\n        .join(` sheet_name = \"${action.payload.name}`);\n      return {\n        ...state,\n        template,\n        loading: false,\n        details: action.payload,\n      };\n    case EDIT_CLASS:\n      template = state.template\n        .split(`class ${state.details.class_name}(scrapy.Spider):`)\n        .join(`class ${action.payload.class_name}(scrapy.Spider):`)\n        .split(\n          `sonic.spiders.regulation_spiders import ${state.details.class_name}`\n        )\n        .join(\n          `sonic.spiders.regulation_spiders import ${action.payload.class_name}`\n        )\n        .split(`sonic.spiders.news_spiders import ${state.details.class_name}`)\n        .join(`sonic.spiders.news_spiders import ${action.payload.class_name}`)\n        .split(`Test${state.details.class_name}`)\n        .join(`Test${action.payload.class_name}`)\n        .split(`spider = ${state.details.class_name}`)\n        .join(`spider = ${action.payload.class_name}`);\n      return {\n        ...state,\n        template,\n        loading: false,\n        details: action.payload,\n      };\n    case EDIT_COUNTRY:\n      template = state.template\n        .split(`country = \"${state.details.country}\"`)\n        .join(`country = \"${action.payload.country}\"`);\n      return {\n        ...state,\n        template,\n        loading: false,\n        details: action.payload,\n      };\n    case EDIT_REG:\n      template = state.template\n        .split(`regulator = \"${state.details.regulator}\"`)\n        .join(`regulator = \"${action.payload.regulator}\"`);\n      return {\n        ...state,\n        template,\n        loading: false,\n        details: action.payload,\n      };\n    case EDIT_REG_FULL:\n      template = state.template\n        .split(`regulator_full_name = \"${state.details.regulator_full_name}\"`)\n        .join(`regulator_full_name = \"${action.payload.regulator_full_name}\"`);\n      return {\n        ...state,\n        template,\n        loading: false,\n        details: action.payload,\n      };\n    case EDIT_URL:\n      template = state.template\n        .split(`main_url = \"${state.details.main_url}\"`)\n        .join(`main_url = \"${action.payload.main_url}\"`);\n      return {\n        ...state,\n        template,\n        loading: false,\n        details: action.payload,\n      };\n    case ERROR:\n      return state;\n    default:\n      return state;\n  }\n}\n","import { combineReducers } from \"redux\";\nimport scraper from \"./scraper\";\n\nexport default combineReducers({\n  scraper,\n});\n","import { composeWithDevTools } from \"redux-devtools-extension\";\nimport { createStore, applyMiddleware } from \"redux\";\nimport { Provider } from \"react-redux\";\nimport thunk from \"redux-thunk\";\nimport React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport \"./index.css\";\nimport App from \"./App\";\nimport * as serviceWorker from \"./serviceWorker\";\nimport rootReducers from \"./reducers/rootReducers\";\nconst initialState = {};\nconst middleware = [thunk];\nconst store = createStore(\n  rootReducers,\n  initialState,\n  composeWithDevTools(applyMiddleware(...middleware))\n);\nReactDOM.render(\n  <React.StrictMode>\n    <Provider store={store}>\n      <App />\n    </Provider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n);\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}